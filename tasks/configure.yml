---
- name: Create file yarn-site.xml
  template:
    src: yarn-site.xml
    dest: "{{ hadoop_home }}/etc/hadoop/yarn-site.xml"
    owner: "{{ hadoop_system_user }}"
    group: "{{ hadoop_system_group }}"
#  notify:
#    - restart hadoop-dfs
#    - restart yarn-resourcemanager
#    - restart hadoop-datanode
#    - restart yarn-nodemanager
  tags:
    - configure
    - yarn_site

- name: Create file hdfs-site.xml
  template:
    src: "hdfs-site.xml"
    dest: "{{ hadoop_home }}/etc/hadoop/hdfs-site.xml"
    owner: "{{ hadoop_system_user }}"
    group: "{{ hadoop_system_group }}"
#  notify:
#    - restart hadoop-dfs
#    - restart yarn-resourcemanager
#    - restart hadoop-datanode
#    - restart yarn-nodemanager
  tags:
    - configure

- name: Create file core-site.xml
  template:
    src: "core-site.xml"
    dest: "{{ hadoop_home }}/etc/hadoop/core-site.xml"
    owner: "{{ hadoop_system_user }}"
    group: "{{ hadoop_system_group }}"
#  notify:
#    - restart hadoop-dfs
#    - restart yarn-resourcemanager
#    - restart hadoop-datanode
#    - restart yarn-nodemanager
  tags:
    - configure

- name: Create file slaves
  template:
    src: slaves
    dest: "{{ hadoop_home }}/etc/hadoop/slaves"
    owner: "{{ hadoop_system_user }}"
    group: "{{ hadoop_system_group }}"
#  notify:
#    - refreshDFSNodes
#    - refreshYarnNodes
#    - restart hadoop-datanode
#    - restart yarn-nodemanager
  tags:
    - configure

- name: Create file workers
  template:
    src: slaves
    dest: "{{ hadoop_home }}/etc/hadoop/workers"
    owner: "{{ hadoop_system_user }}"
    group: "{{ hadoop_system_group }}"
  tags:
    - configure

- name: Set data dir from hdfs_props
  set_fact: data_dir={{ hdfs_props['dfs.namenode.name.dir'][7:] }}
  when: hdfs_props['dfs.namenode.name.dir'] is defined
  tags:
    - configure

- name: Set default data dir
  set_fact: data_dir=/tmp/hadoop-root/dfs
  when: hdfs_props['dfs.namenode.name.dir'] is undefined
  tags:
    - configure

- name: Format namenode data dir
  command: "{{ hadoop_home }}/bin/hdfs namenode -format"
  args:
    creates: "{{data_dir}}"
  when: (hadoop_type_of_node == 'master') or (hadoop_type_of_node == 'namenode')
  tags:
    - configure

- name: Open external ports
  iptables: chain=INPUT jump=ACCEPT protocol=tcp destination_port={{item}}
  ignore_errors: yes
  with_items:
    - 8088
    - 50030
    - 8030
    - 8031
    - 8032
  tags:
    - configure

- name: Open all ports from ip {{ item.1 }} in the firewall
  iptables: chain=INPUT jump=ACCEPT protocol=tcp source {{ item.1 }}
  ignore_errors: yes
  with_together:
    - groups.all
    - ansible_all_ipv4_addresses
  tags:
    - configure


